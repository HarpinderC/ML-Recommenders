{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# MovieLens 100K Recommender System - Phase 3\n",
        "## Matrix Factorization (SVD, SVD++, NMF, ALS)\n",
        "\n",
        "**Project:** Hybrid Movie Recommendation System  \n",
        "**Dataset:** MovieLens 100K  \n",
        "**Author:** Harpinder Singh  \n",
        "**Date:** December 2025  \n",
        "**Best CF RMSE to Beat:** 0.9402"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
        "## â•‘                    IMPORTS & SETUP                        â•‘\n",
        "## â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Libraries imported successfully\n",
            "ğŸ“… Execution Date: February 01, 2026\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\aekas\\anaconda3\\envs\\Development\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datetime import datetime\n",
        "import warnings\n",
        "from scipy.sparse import csr_matrix\n",
        "\n",
        "# Surprise library for matrix factorization\n",
        "from surprise import Dataset, Reader, SVD, SVDpp, NMF\n",
        "from surprise.model_selection import train_test_split, GridSearchCV\n",
        "from surprise import accuracy\n",
        "\n",
        "# Implicit library for ALS\n",
        "from implicit.als import AlternatingLeastSquares\n",
        "from implicit.evaluation import train_test_split as implicit_split\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "np.random.seed(42)\n",
        "\n",
        "# Plot styling\n",
        "plt.style.use('seaborn-v0_8-darkgrid')\n",
        "sns.set_palette('husl')\n",
        "\n",
        "print(\"âœ… Libraries imported successfully\")\n",
        "print(f\"ğŸ“… Execution Date: {datetime.now().strftime('%B %d, %Y')}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
        "## â•‘                  LOAD PREVIOUS RESULTS                    â•‘\n",
        "## â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ“Š Dataset Loaded:\n",
            "   Shape: (100000, 10)\n",
            "\n",
            "ğŸ“Š Previous Best Results (Phase 2):\n",
            "                  Model     RMSE      MAE\n",
            "  Item-Based CF (Means) 0.940247 0.739867\n",
            "Item-Based CF (Z-Score) 0.942329 0.740470\n",
            "  User-Based CF (Means) 0.953842 0.752562\n",
            "\n",
            "ğŸ¯ Target to Beat: RMSE < 0.9402\n"
          ]
        }
      ],
      "source": [
        "# â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
        "# â”‚ Load Data & Previous Results            â”‚\n",
        "# â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
        "\n",
        "data = pd.read_csv('../data/movielens_100k_merged.csv')\n",
        "cf_results = pd.read_csv('../results/cf_results.csv')\n",
        "\n",
        "print(\"ğŸ“Š Dataset Loaded:\")\n",
        "print(f\"   Shape: {data.shape}\")\n",
        "\n",
        "print(\"\\nğŸ“Š Previous Best Results (Phase 2):\")\n",
        "print(cf_results.head(3).to_string(index=False))\n",
        "\n",
        "best_cf_rmse = cf_results['RMSE'].min()\n",
        "print(f\"\\nğŸ¯ Target to Beat: RMSE < {best_cf_rmse:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ“Š Data Prepared:\n",
            "   Training samples: 80,000\n",
            "   Test samples:     20,000\n"
          ]
        }
      ],
      "source": [
        "# â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
        "# â”‚ Prepare Data for Surprise               â”‚\n",
        "# â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
        "\n",
        "reader = Reader(rating_scale=(1, 5))\n",
        "surprise_data = Dataset.load_from_df(data[['user_id', 'item_id', 'rating']], reader)\n",
        "trainset, testset = train_test_split(surprise_data, test_size=0.2, random_state=42)\n",
        "\n",
        "print(\"ğŸ“Š Data Prepared:\")\n",
        "print(f\"   Training samples: {trainset.n_ratings:,}\")\n",
        "print(f\"   Test samples:     {len(testset):,}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
        "## â•‘              SINGULAR VALUE DECOMPOSITION (SVD)           â•‘\n",
        "## â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ”¢ SVD (Singular Value Decomposition) - Default\n",
            "============================================================\n",
            "RMSE: 0.9352\n",
            "MAE:  0.7375\n",
            "\n",
            "Improvement over best CF: 0.54%\n"
          ]
        }
      ],
      "source": [
        "# â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
        "# â”‚ SVD - Default Parameters                â”‚\n",
        "# â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
        "\n",
        "print(\"ğŸ”¢ SVD (Singular Value Decomposition) - Default\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Train SVD model\n",
        "svd_default = SVD(random_state=42, verbose=False)\n",
        "svd_default.fit(trainset)\n",
        "\n",
        "# Predict on test set\n",
        "predictions_svd_default = svd_default.test(testset)\n",
        "\n",
        "# Calculate metrics\n",
        "rmse_svd_default = accuracy.rmse(predictions_svd_default, verbose=False)\n",
        "mae_svd_default = accuracy.mae(predictions_svd_default, verbose=False)\n",
        "\n",
        "print(f\"RMSE: {rmse_svd_default:.4f}\")\n",
        "print(f\"MAE:  {mae_svd_default:.4f}\")\n",
        "print(f\"\\nImprovement over best CF: {((best_cf_rmse - rmse_svd_default) / best_cf_rmse * 100):.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ğŸ”§ SVD - Hyperparameter Tuning\n",
            "============================================================\n",
            "\n",
            "ğŸ† Best Parameters:\n",
            "{'n_factors': 50, 'n_epochs': 20, 'lr_all': 0.01, 'reg_all': 0.05}\n",
            "\n",
            "ğŸ“Š Best Cross-Validation RMSE: 0.9316\n",
            "\n",
            "ğŸ“Š Test Set Performance:\n",
            "RMSE: 0.9190\n",
            "MAE:  0.7229\n",
            "\n",
            "Improvement over best CF: 2.26%\n"
          ]
        }
      ],
      "source": [
        "# â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
        "# â”‚ SVD - Hyperparameter Tuning             â”‚\n",
        "# â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
        "\n",
        "print(\"\\nğŸ”§ SVD - Hyperparameter Tuning\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Define parameter grid\n",
        "param_grid = {\n",
        "    'n_factors': [50, 100, 150],\n",
        "    'n_epochs': [20, 30],\n",
        "    'lr_all': [0.005, 0.01],\n",
        "    'reg_all': [0.02, 0.05]\n",
        "}\n",
        "\n",
        "# Grid search with cross-validation\n",
        "gs_svd = GridSearchCV(SVD, param_grid, measures=['rmse', 'mae'], cv=3, n_jobs=-1)\n",
        "gs_svd.fit(surprise_data)\n",
        "\n",
        "# Best parameters\n",
        "print(\"\\nğŸ† Best Parameters:\")\n",
        "print(gs_svd.best_params['rmse'])\n",
        "\n",
        "# Best scores\n",
        "print(f\"\\nğŸ“Š Best Cross-Validation RMSE: {gs_svd.best_score['rmse']:.4f}\")\n",
        "\n",
        "# Train best model on full trainset\n",
        "svd_tuned = gs_svd.best_estimator['rmse']\n",
        "svd_tuned.fit(trainset)\n",
        "\n",
        "# Predict on test set\n",
        "predictions_svd_tuned = svd_tuned.test(testset)\n",
        "\n",
        "# Calculate metrics\n",
        "rmse_svd_tuned = accuracy.rmse(predictions_svd_tuned, verbose=False)\n",
        "mae_svd_tuned = accuracy.mae(predictions_svd_tuned, verbose=False)\n",
        "\n",
        "print(f\"\\nğŸ“Š Test Set Performance:\")\n",
        "print(f\"RMSE: {rmse_svd_tuned:.4f}\")\n",
        "print(f\"MAE:  {mae_svd_tuned:.4f}\")\n",
        "print(f\"\\nImprovement over best CF: {((best_cf_rmse - rmse_svd_tuned) / best_cf_rmse * 100):.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
        "## â•‘                    SVD++ (Enhanced SVD)                   â•‘\n",
        "## â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ğŸ”¢ SVD++ (SVD with Implicit Feedback)\n",
            "============================================================\n",
            "âš ï¸  Note: SVD++ is slower but often more accurate\n",
            "\n",
            "RMSE: 0.9200\n",
            "MAE:  0.7198\n",
            "\n",
            "Improvement over best CF: 2.15%\n"
          ]
        }
      ],
      "source": [
        "# â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
        "# â”‚ SVD++ - With Implicit Feedback          â”‚\n",
        "# â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
        "\n",
        "print(\"\\nğŸ”¢ SVD++ (SVD with Implicit Feedback)\")\n",
        "print(\"=\" * 60)\n",
        "print(\"âš ï¸  Note: SVD++ is slower but often more accurate\\n\")\n",
        "\n",
        "# Train SVD++ model\n",
        "svdpp_model = SVDpp(random_state=42, verbose=False)\n",
        "svdpp_model.fit(trainset)\n",
        "\n",
        "# Predict on test set\n",
        "predictions_svdpp = svdpp_model.test(testset)\n",
        "\n",
        "# Calculate metrics\n",
        "rmse_svdpp = accuracy.rmse(predictions_svdpp, verbose=False)\n",
        "mae_svdpp = accuracy.mae(predictions_svdpp, verbose=False)\n",
        "\n",
        "print(f\"RMSE: {rmse_svdpp:.4f}\")\n",
        "print(f\"MAE:  {mae_svdpp:.4f}\")\n",
        "print(f\"\\nImprovement over best CF: {((best_cf_rmse - rmse_svdpp) / best_cf_rmse * 100):.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
        "## â•‘       NON-NEGATIVE MATRIX FACTORIZATION (NMF)            â•‘\n",
        "## â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ğŸ”¢ NMF (Non-Negative Matrix Factorization)\n",
            "============================================================\n",
            "RMSE: 0.9594\n",
            "MAE:  0.7533\n",
            "\n",
            "Improvement over best CF: -2.04%\n"
          ]
        }
      ],
      "source": [
        "# â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
        "# â”‚ NMF - Default Parameters                â”‚\n",
        "# â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
        "\n",
        "print(\"\\nğŸ”¢ NMF (Non-Negative Matrix Factorization)\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Train NMF model\n",
        "nmf_model = NMF(random_state=42, verbose=False)\n",
        "nmf_model.fit(trainset)\n",
        "\n",
        "# Predict on test set\n",
        "predictions_nmf = nmf_model.test(testset)\n",
        "\n",
        "# Calculate metrics\n",
        "rmse_nmf = accuracy.rmse(predictions_nmf, verbose=False)\n",
        "mae_nmf = accuracy.mae(predictions_nmf, verbose=False)\n",
        "\n",
        "print(f\"RMSE: {rmse_nmf:.4f}\")\n",
        "print(f\"MAE:  {mae_nmf:.4f}\")\n",
        "print(f\"\\nImprovement over best CF: {((best_cf_rmse - rmse_nmf) / best_cf_rmse * 100):.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
        "## â•‘       ALTERNATING LEAST SQUARES (ALS) - Implicit         â•‘\n",
        "## â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ğŸ”¢ ALS (Alternating Least Squares) - Implicit Library\n",
            "============================================================\n",
            "User-Item Matrix Shape: (943, 1682)\n",
            "Sparsity: 93.70%\n"
          ]
        }
      ],
      "source": [
        "# â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
        "# â”‚ Prepare Sparse Matrix for ALS          â”‚\n",
        "# â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
        "\n",
        "print(\"\\nğŸ”¢ ALS (Alternating Least Squares) - Implicit Library\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Create user-item matrix\n",
        "train_data_als = data[['user_id', 'item_id', 'rating']].copy()\n",
        "\n",
        "# Create mappings\n",
        "user_ids = train_data_als['user_id'].unique()\n",
        "item_ids = train_data_als['item_id'].unique()\n",
        "\n",
        "user_map = {uid: idx for idx, uid in enumerate(user_ids)}\n",
        "item_map = {iid: idx for idx, iid in enumerate(item_ids)}\n",
        "\n",
        "train_data_als['user_idx'] = train_data_als['user_id'].map(user_map)\n",
        "train_data_als['item_idx'] = train_data_als['item_id'].map(item_map)\n",
        "\n",
        "# Create sparse matrix\n",
        "user_item_matrix = csr_matrix(\n",
        "    (train_data_als['rating'].values, \n",
        "     (train_data_als['user_idx'].values, train_data_als['item_idx'].values)),\n",
        "    shape=(len(user_ids), len(item_ids))\n",
        ")\n",
        "\n",
        "print(f\"User-Item Matrix Shape: {user_item_matrix.shape}\")\n",
        "print(f\"Sparsity: {(1 - user_item_matrix.nnz / (user_item_matrix.shape[0] * user_item_matrix.shape[1])) * 100:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:00<00:00, 89.29it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "âœ… ALS model trained successfully\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
        "# â”‚ Train ALS Model                         â”‚\n",
        "# â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
        "\n",
        "# Train ALS model\n",
        "als_model = AlternatingLeastSquares(\n",
        "    factors=100,\n",
        "    regularization=0.01,\n",
        "    iterations=30,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "als_model.fit(user_item_matrix)\n",
        "\n",
        "print(\"\\nâœ… ALS model trained successfully\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ğŸ“Š ALS Performance:\n",
            "RMSE: 2.7473\n",
            "MAE:  2.5061\n",
            "\n",
            "Improvement over best CF: -192.19%\n"
          ]
        }
      ],
      "source": [
        "# â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
        "# â”‚ Evaluate ALS on Test Set                â”‚\n",
        "# â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
        "\n",
        "# Manual test set evaluation (since Surprise testset format differs)\n",
        "test_predictions_als = []\n",
        "test_actuals = []\n",
        "\n",
        "for uid, iid, actual in testset:\n",
        "    # Map to indices\n",
        "    if uid in user_map and iid in item_map:\n",
        "        user_idx = user_map[uid]\n",
        "        item_idx = item_map[iid]\n",
        "        \n",
        "        # Predict\n",
        "        prediction = als_model.user_factors[user_idx].dot(als_model.item_factors[item_idx])\n",
        "        \n",
        "        # Clip to rating scale\n",
        "        prediction = np.clip(prediction, 1, 5)\n",
        "        \n",
        "        test_predictions_als.append(prediction)\n",
        "        test_actuals.append(actual)\n",
        "\n",
        "# Calculate metrics\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "from math import sqrt\n",
        "\n",
        "rmse_als = sqrt(mean_squared_error(test_actuals, test_predictions_als))\n",
        "mae_als = mean_absolute_error(test_actuals, test_predictions_als)\n",
        "\n",
        "print(f\"\\nğŸ“Š ALS Performance:\")\n",
        "print(f\"RMSE: {rmse_als:.4f}\")\n",
        "print(f\"MAE:  {mae_als:.4f}\")\n",
        "print(f\"\\nImprovement over best CF: {((best_cf_rmse - rmse_als) / best_cf_rmse * 100):.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
        "## â•‘          COMPARE ALL MATRIX FACTORIZATION MODELS         â•‘\n",
        "## â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Development",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
